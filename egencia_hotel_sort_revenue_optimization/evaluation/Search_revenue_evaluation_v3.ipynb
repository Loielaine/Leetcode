{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>43</td><td>application_1600892099892_0044</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-40-9-71.us-west-2.compute.internal:20888/proxy/application_1600892099892_0044/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-40-9-79.us-west-2.compute.internal:8042/node/containerlogs/container_1600892099892_0044_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.types import IntegerType,FloatType,DoubleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Read Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the prediction from the model with data ranged from 10/01/2019 - 01/01/2020.\n",
    "prediction = sqlContext.read.parquet('s3://ege-ds-workshops-corp/yixli/prediction/prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculate normalized rate revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateNormalizedRateRevenue(prediction):\n",
    "    # sum probabilities by hotel\n",
    "    prediction = prediction.withColumn('sum_prob',F.sum('prob').over(Window.partitionBy(\"message_id\",\"hotel_id\",\"check_in_date\",\"check_out_date\",'tuid')))\n",
    "\n",
    "    # normalized rate-picking up probabilities\n",
    "    prediction = prediction.withColumn('normalized_prob',F.col('prob')/F.col('sum_prob'))\n",
    "\n",
    "    # normalized rate revenue\n",
    "    prediction = prediction.withColumn('normalized_rate_revenue',F.col('normalized_prob')*F.col('src_supply_revenue_usd'))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sum rate level revenue to hotel level revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  calculateNormalizedHotelRevenue(prediction):\n",
    "    # get duration of stay\n",
    "    prediction = prediction.\\\n",
    "                         withColumn('duration', F.datediff(F.col(\"check_out_date\"),F.col( \"check_in_date\")).cast(IntegerType()))\n",
    "    # get hotel revenue df by sum up rate revenue for each hotel\n",
    "    revenue_prediction = prediction.withColumn('normalized_hotel_revenue',\n",
    "                                       F.sum(F.col('normalized_rate_revenue')*F.col('duration')).\\\n",
    "                                       over(Window.partitionBy(\"message_id\",\"hotel_id\",\"check_in_date\",\"check_out_date\",'tuid'))).\\\n",
    "                            select(\"message_id\",\"hotel_id\",\"check_in_date\",\"check_out_date\",\"tuid\",'normalized_hotel_revenue','hotel_index','score_1','bk_hotel_index','message_date').\\\n",
    "                            dropDuplicates()\n",
    "    return revenue_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBands(n_band,revenue_prediction):\n",
    "    # exclude those hotels whose scores are NULL\n",
    "    revenue_prediction = revenue_prediction.filter(F.col('score_1').isNotNull())\n",
    "    # create band_df with upper and lower bounds of each band\n",
    "    band_df = revenue_prediction.\\\n",
    "    groupby(\"message_id\", \"tuid\").\\\n",
    "    agg(F.count(\"hotel_id\").alias(\"n\"),F.max(\"score_1\").alias(\"ub\"),F.min(\"score_1\").alias(\"lb\")).\\\n",
    "    filter(F.col(\"n\")>=1).\\\n",
    "    filter(F.col(\"n\")<=30).\\\n",
    "    withColumn(\"n_band\", F.lit(n_band)).\\\n",
    "    withColumn(\"sz_band\", F.expr(\"(ub - lb)/n_band\")).\\\n",
    "    select(\"message_id\", \"tuid\", \"sz_band\", \"ub\", \"lb\")\n",
    "    # join hotel revenue df to get band for each hotel\n",
    "    revenue_prediction2 = revenue_prediction.\\\n",
    "    join(band_df, [\"message_id\", \"tuid\"]).\\\n",
    "    withColumn(\"band\", F.when(F.col(\"sz_band\") == 0, 1).otherwise(F.expr(\"int((score_1-lb)/sz_band)\")))\n",
    "    return revenue_prediction2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 New revenue with normalized probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewHotelIndex(revenue_prediction2):\n",
    "    # add month column to df\n",
    "    revenue_prediction2 = revenue_prediction2.withColumn('month',F.month('message_date'))\n",
    "    # Sort by 'normalized_hotel_revenue' and obtain the new hotel index\n",
    "    revenue_prediction2 = revenue_prediction2.\\\n",
    "    withColumn(\"band_index_normalized\", row_number().over(Window.partitionBy(\"message_id\", \"tuid\",\"band\").\\\n",
    "                                                          orderBy(F.desc('normalized_hotel_revenue')))).\\\n",
    "    withColumn(\"new_hotel_index2\", row_number().over(Window.partitionBy(\"message_id\", \"tuid\").\\\n",
    "                                                    orderBy(F.asc(\"band\"),F.asc(\"band_index_normalized\"))))\n",
    "    return revenue_prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|sum(normalized_hotel_revenue)|\n",
      "+-----------------------------+\n",
      "|         2.8679587695917085E7|\n",
      "+-----------------------------+"
     ]
    }
   ],
   "source": [
    "# total supply revenue\n",
    "revenue_prediction2.filter(F.col('bk_hotel_index')==F.col('new_hotel_index2')).\\\n",
    "select('normalized_hotel_revenue').\\\n",
    "agg(F.sum('normalized_hotel_revenue')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------+------------+\n",
      "|month|sum(normalized_hotel_revenue)|count(month)|\n",
      "+-----+-----------------------------+------------+\n",
      "|   12|           7795188.4543378055|      130326|\n",
      "|    1|            10532.18705316058|          99|\n",
      "|   10|         1.1140306050966235E7|      183587|\n",
      "|   11|            9733561.003559899|      167541|\n",
      "+-----+-----------------------------+------------+"
     ]
    }
   ],
   "source": [
    "# supply revenue by month\n",
    "revenue_prediction2.filter(F.col('bk_hotel_index')==F.col('new_hotel_index2')).\\\n",
    "select('normalized_hotel_revenue','month').\\\n",
    "groupBy('month').agg(F.sum('normalized_hotel_revenue'),F.count('month')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hotel revenue df\n",
    "dir = 's3://ege-ds-workshops-corp/yixli/prediction/'\n",
    "revenue_prediction2.repartition(1).write.mode('overwrite').parquet(dir+'revenue_estimation3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
