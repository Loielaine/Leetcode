{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Code-to-run-the-notebook\" data-toc-modified-id=\"Code-to-run-the-notebook-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code to run the notebook</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code-running-locally\" data-toc-modified-id=\"Code-running-locally-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Code running locally</a></span></li><li><span><a href=\"#Code-running-on-the-cluster\" data-toc-modified-id=\"Code-running-on-the-cluster-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Code running on the cluster</a></span></li><li><span><a href=\"#Loading-variables\" data-toc-modified-id=\"Loading-variables-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Loading variables</a></span></li><li><span><a href=\"#Downloading-values\" data-toc-modified-id=\"Downloading-values-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Downloading values</a></span></li></ul></li><li><span><a href=\"#Presentation-of-the-dataset\" data-toc-modified-id=\"Presentation-of-the-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Presentation of the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-sources\" data-toc-modified-id=\"Data-sources-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data sources</a></span></li><li><span><a href=\"#Dataset-contents\" data-toc-modified-id=\"Dataset-contents-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Dataset contents</a></span><ul class=\"toc-item\"><li><span><a href=\"#Description-of-the-data\" data-toc-modified-id=\"Description-of-the-data-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Description of the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Some-stats-on-the-dataset\" data-toc-modified-id=\"Some-stats-on-the-dataset-3.2.1.1\"><span class=\"toc-item-num\">3.2.1.1&nbsp;&nbsp;</span>Some stats on the dataset</a></span></li></ul></li><li><span><a href=\"#Profiling-report\" data-toc-modified-id=\"Profiling-report-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Profiling report</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Data-preprocessing-and-cleaning\" data-toc-modified-id=\"Data-preprocessing-and-cleaning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data preprocessing and cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Missing-values\" data-toc-modified-id=\"Missing-values-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Missing values</a></span></li><li><span><a href=\"#Duplicates\" data-toc-modified-id=\"Duplicates-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Duplicates</a></span></li><li><span><a href=\"#Wrong-values\" data-toc-modified-id=\"Wrong-values-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Wrong values</a></span></li><li><span><a href=\"#Data-standardization\" data-toc-modified-id=\"Data-standardization-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Data standardization</a></span></li><li><span><a href=\"#Remove-or-fix-outliers\" data-toc-modified-id=\"Remove-or-fix-outliers-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Remove or fix outliers</a></span></li><li><span><a href=\"#Some-stats-of-the-dataset-after-data-preprossing-and-data-cleaning\" data-toc-modified-id=\"Some-stats-of-the-dataset-after-data-preprossing-and-data-cleaning-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Some stats of the dataset after data preprossing and data cleaning</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Dataset-exploration\" data-toc-modified-id=\"Dataset-exploration-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Dataset exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exploration-of-target-variables\" data-toc-modified-id=\"Exploration-of-target-variables-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Exploration of target variables</a></span></li><li><span><a href=\"#Exploration-of-relationship-between-input-variables\" data-toc-modified-id=\"Exploration-of-relationship-between-input-variables-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Exploration of relationship between input variables</a></span></li><li><span><a href=\"#Outlier-detection\" data-toc-modified-id=\"Outlier-detection-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Outlier detection</a></span></li><li><span><a href=\"#More-data-exploration\" data-toc-modified-id=\"More-data-exploration-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>More data exploration</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "On this section we will provide the goals of this notebook. What kind of information we are trying to extract from the datasets that will be explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to run the notebook\n",
    "On this section we will provide the code to run the notebook. The goal being to have all the functions used in the notebook here, so that after this section the notebook is as clean as possible as with as few code as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code running locally\n",
    "On this section we will add the code that will run locally. Here we put some functions that we believe they can be useful for any notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot, plot\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "from plotly.grid_objs import Column, Grid\n",
    "init_notebook_mode(connected=True)\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "def build_table(df):\n",
    "    trace = go.Table(\n",
    "    header=dict(values=list(df.columns),\n",
    "                fill = dict(color='#C2D4FF'),\n",
    "                align = ['left'] * 5,\n",
    "                font=dict(size=10)),\n",
    "    cells=dict(values=[df[k].tolist() for k in df.columns[0:]],\n",
    "               fill = dict(color='#F5F8FF'), font=dict(size=10)))\n",
    "    data = [trace]\n",
    "    return data\n",
    "\n",
    "def add_percentage_of_runs_out_of_total_runs_to_data_frame(df):\n",
    "    df['percentage_runs'] = df['count']/df['count'].sum()\n",
    "    df = df.sort_values(by='percentage_runs', ascending=False)\n",
    "    df['run_id'] = df['run_id'].apply(str)\n",
    "    return df\n",
    "\n",
    "def overlay_histograms(first_distribution_values, second_distribution_values, first_distribution_name, second_distribution_name):\n",
    "    data = [go.Histogram(x=first_distribution_values, opacity=1, histnorm='probability', name = first_distribution_name, marker=dict(\n",
    "        color='rgb(0, 0, 100)'\n",
    "    ))]\n",
    "    data += [go.Histogram(x=second_distribution_values, opacity=0.75, histnorm='probability', name = second_distribution_name, marker=dict(\n",
    "        color='#EB89B5'\n",
    "    ))]\n",
    "    return data\n",
    "\n",
    "def overlay_line_graphs(first_distribution_values, second_distribution_values, \n",
    "                        first_distribution_name, second_distribution_name):\n",
    "    # Group data together\n",
    "    hist_data = [first_distribution_values, second_distribution_values]\n",
    "\n",
    "    group_labels = [first_distribution_name, second_distribution_name]\n",
    "    colors = ['rgb(0, 0, 100)', '#EB89B5']\n",
    "    # Create distplot with custom bin_size\n",
    "    fig = ff.create_distplot(hist_data, group_labels, bin_size=[1, .5], colors=colors, show_hist=False)\n",
    "    return fig\n",
    "\n",
    "def count_na(df):\n",
    "    sum_series = df.isnull().sum(axis=0)\n",
    "    return pd.DataFrame({'column':sum_series.index, 'sum':sum_series.values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code running on the cluster\n",
    "Here we will add all the functions necessary to run code on the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics \n",
    "from pyspark.sql.types import StringType, StructType, StructField, IntegerType\n",
    "from pyspark.mllib.linalg import Matrices, Vectors\n",
    "\n",
    "def get_dataset_stats(df):\n",
    "    return df.describe()\n",
    "\n",
    "def get_dataset_without_duplicates(df):\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "def count_duplicates(df):\n",
    "    duplicates_schema = StructType([\n",
    "        StructField(\"Count\", StringType(), False)\n",
    "     ])\n",
    "\n",
    "    dup_data = sc.parallelize([str(df.count() - df.drop_duplicates().count())])\n",
    "    dup_data = dup_data.map(lambda x: (x,))\n",
    "    return spark.createDataFrame(dup_data, schema=duplicates_schema)\n",
    "\n",
    "def count_nan(df):\n",
    "    return df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "def compute_statistics(df, col_name):\n",
    "    stats_schema = StructType([\n",
    "        StructField(\"Metric\", StringType(), True),\n",
    "        StructField(\"Value\", StringType(), True)\n",
    "     ])\n",
    "    \n",
    "    x = df.select(col_name)\n",
    "    rdd = x.rdd.map(lambda data: Vectors.dense([c for c in data]))\n",
    "    summary = Statistics.colStats(rdd)\n",
    "    median = x.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    counts = x.groupBy(col_name).count().sort(\"count\", ascending = False)\n",
    "    mode = counts.first()[col_name]\n",
    "    stats_data = [('Mode', str(mode)), ('Median', str(median)), ('Mean', str(summary.mean()[0])), ('Variance', str(summary.variance()[0])), ('Coefficient of variation', str(sqrt(summary.variance()[0])/summary.mean()[0])), ('Max value', str(summary.max()[0])), ('Min value', str(summary.min()[0])), ('Total value count', str(summary.count())), ('Number of non-zero values', str(summary.numNonzeros()[0]))]                \n",
    "    stats_df = spark.createDataFrame(stats_data, schema=stats_schema)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading variables\n",
    "On this section we will load all the variables necessary to be downloaded locally for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading values\n",
    "On this section we will download the variables loaded above into our local environment. \n",
    "\n",
    "Example:\n",
    "<code>%%spark -o df_hotel_events -m sample --maxrows 10</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation of the dataset\n",
    "On this section we will give a quick overview of the dataset.\n",
    "\n",
    "We will describe:\n",
    "<ul>\n",
    "    <li>The sources: where the data comes from</li>\n",
    "    <li>The content: display of the dataset contents in a table</li>\n",
    "    <li>The columns: description of each column</li>\n",
    "    <li>Some stats: count, median of values, nb of unique values, NA values, etc</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "Here if possible we will add a diagram explaining where the data is coming from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset contents\n",
    "Contents of the dataset will be described here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%local\n",
    "# Table with the contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the data\n",
    "Here we will describe each column of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%local\n",
    "# Use here function count_na to have a dataframe describing how many missing values on each column of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some stats on the dataset\n",
    "We can use this section to give some basic statistics on each column of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling report\n",
    "Can use profiling frameworks for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "A brief conclusion describing the findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and cleaning\n",
    "On this section we will:\n",
    "<ul>\n",
    "    <li>Remove or fix missing values</li>\n",
    "    <li>Remove or fix duplicates</li>\n",
    "    <li>Do any kind of data standardization: Time zone conversion, currency conversion</li>\n",
    "    <li>Remove or fix wrong values: e.g. Negative prices</li>\n",
    "    <li>Remove or fix outliers</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "On this section we will remove or fix missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "On this section we will remove or fix duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong values\n",
    "Here we will remove wrong values: example: negative prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization\n",
    "Here we will do standardization work: convert all values to the same currency, same timezone, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove or fix outliers\n",
    "We will do a first search for outliers and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some stats of the dataset after data preprossing and data cleaning\n",
    "We will display some basic statistics of the dataset after data preprocessing and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Quick conclusion of the findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset exploration\n",
    "On this section we will go deeper into the dataset\n",
    "\n",
    "Here we will:\n",
    "\n",
    "<ul>\n",
    "    <li>Explore target variables if applicable</li>\n",
    "    <li>Explore relationships between variables</li>\n",
    "    <li>Find outliers</li>\n",
    "    <li><b>Do any kind of exploration allowing us to reach the goals of the notebook</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of target variables\n",
    "On this section we will see how target variables are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of relationship between input variables\n",
    "On this section we will see how input variables correlate among themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection\n",
    "Here we will handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data exploration\n",
    "<ul>\n",
    "    <li>How much money can we make from this project?</li>\n",
    "    <li>How much can Egencia save?</li>\n",
    "    <li>Any other missing data exploration in accordance to the goals of the notebook</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Conclusions for the notebook. Must be aligned with the goals described at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
